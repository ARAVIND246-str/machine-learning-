{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "\n",
        "# Download stopwords list if not already present\n",
        "try:\n",
        "    stopwords.words('english')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "\n",
        "# --- 1. Data Loading (FIXED for KeyError) ---\n",
        "try:\n",
        "    # Load the CSV\n",
        "    df = pd.read_csv('/content/email_spam.csv', encoding='latin-1')\n",
        "\n",
        "    # Assume the dataset has columns: 'text' and 'type' (based on previous outputs)\n",
        "    df = df[['type', 'text']].rename(columns={'type': 'label'})\n",
        "\n",
        "    # --- 1b. Data Cleaning (FIX for ValueError: Input y contains NaN) ---\n",
        "    # Drop rows where either 'label' or 'text' column has a missing value (NaN)\n",
        "    print(f\"Original shape: {df.shape}\")\n",
        "    df.dropna(subset=['label', 'text'], inplace=True)\n",
        "    print(f\"Shape after dropping NaNs: {df.shape}\")\n",
        "\n",
        "    # Inspect unique values in the 'label' column before mapping\n",
        "    print(\"\\nUnique values in 'label' column before mapping:\")\n",
        "    print(df['label'].unique())\n",
        "\n",
        "\n",
        "    # Convert labels to binary (0 for 'not spam', 1 for 'spam')\n",
        "    # Added .str.lower() and .str.strip() to handle potential casing and whitespace issues\n",
        "    df['label'] = df['label'].str.lower().str.strip()\n",
        "    df['label'] = df['label'].map({'not spam': 0, 'spam': 1})\n",
        "\n",
        "\n",
        "    # Remove rows where mapping failed (NaN labels)\n",
        "    df.dropna(subset=['label'], inplace=True)\n",
        "    df['label'] = df['label'].astype(int)   # Ensure label is integer\n",
        "\n",
        "    print(f\"Final shape after mapping and dropping missing labels: {df.shape}\")\n",
        "    print(f\"Label counts:\\n{df['label'].value_counts()}\")\n",
        "\n",
        "    # --- 2. Text Preprocessing Function ---\n",
        "    def preprocess_text(text):\n",
        "        # Ensure text is treated as a string to avoid errors on non-string inputs\n",
        "        text = str(text)\n",
        "        # Remove non-alphabetic characters and convert to lower case\n",
        "        text = re.sub('[^a-zA-Z]', ' ', text).lower()\n",
        "        # Tokenize (split into words)\n",
        "        words = text.split()\n",
        "        # Remove stopwords\n",
        "        words = [w for w in words if w not in stopwords.words('english')]\n",
        "        # Re-join the words into a single string\n",
        "        return ' '.join(words)\n",
        "\n",
        "    # Apply preprocessing to the text column\n",
        "    df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "    # --- 3. Feature Extraction (Vectorization) ---\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        df['cleaned_text'], df['label'], test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Initialize CountVectorizer (Bag-of-Words model)\n",
        "    vectorizer = CountVectorizer(max_features=5000)\n",
        "\n",
        "    # Fit the vectorizer to the training data and transform it\n",
        "    X_train_vec = vectorizer.fit_transform(X_train).toarray()\n",
        "\n",
        "    # Transform the test data using the *fitted* vectorizer\n",
        "    X_test_vec = vectorizer.transform(X_test).toarray()\n",
        "\n",
        "    print(f\"\\nTraining data shape (samples, features): {X_train_vec.shape}\")\n",
        "    print(f\"Testing data shape (samples, features): {X_test_vec.shape}\")\n",
        "\n",
        "\n",
        "    # --- 4. Model Training (Multinomial Naive Bayes) ---\n",
        "    # FIX IS APPLIED: y_train no longer contains NaNs\n",
        "    model = MultinomialNB()\n",
        "    model.fit(X_train_vec, y_train)\n",
        "\n",
        "\n",
        "    # --- 5. Evaluation and Prediction ---\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test_vec)\n",
        "\n",
        "    # Evaluate the model's performance\n",
        "    print(\"\\n--- Model Evaluation ---\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=['Ham', 'Spam']))\n",
        "\n",
        "    # --- Example Spam/Ham Prediction ---\n",
        "    def predict_spam(text_to_check):\n",
        "        cleaned_text = preprocess_text(text_to_check)\n",
        "        # Vectorize the new text (must use the trained vectorizer)\n",
        "        text_vec = vectorizer.transform([cleaned_text]).toarray()\n",
        "        prediction = model.predict(text_vec)[0]\n",
        "        return \"SPAM\" if prediction == 1 else \"HAM\"\n",
        "\n",
        "    # Test the model with new emails\n",
        "    test_email_spam = \"Congratulations! You've won a free iPhone. Click this link immediately to claim your prize.\"\n",
        "    test_email_ham = \"Hey, just following up on our meeting yesterday. Could you send me the revised document by 5 pm?\"\n",
        "\n",
        "    print(\"\\n--- Live Prediction Examples ---\")\n",
        "    print(f\"Email: '{test_email_spam}'\\nPrediction: {predict_spam(test_email_spam)}\")\n",
        "    print(f\"Email: '{test_email_ham}'\\nPrediction: {predict_spam(test_email_ham)}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'email_spam.csv' not found. Please ensure the file is in the correct directory and try again.\")"
      ],
      "metadata": {
        "id": "kfxwYbes9Tkw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ab3207-75eb-422c-8dc8-fcb0c90404d6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (84, 2)\n",
            "Shape after dropping NaNs: (84, 2)\n",
            "\n",
            "Unique values in 'label' column before mapping:\n",
            "['spam' 'not spam']\n",
            "Final shape after mapping and dropping missing labels: (84, 2)\n",
            "Label counts:\n",
            "label\n",
            "0    58\n",
            "1    26\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Training data shape (samples, features): (67, 1829)\n",
            "Testing data shape (samples, features): (17, 1829)\n",
            "\n",
            "--- Model Evaluation ---\n",
            "Accuracy: 0.8235\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         Ham       0.79      1.00      0.88        11\n",
            "        Spam       1.00      0.50      0.67         6\n",
            "\n",
            "    accuracy                           0.82        17\n",
            "   macro avg       0.89      0.75      0.77        17\n",
            "weighted avg       0.86      0.82      0.80        17\n",
            "\n",
            "\n",
            "--- Live Prediction Examples ---\n",
            "Email: 'Congratulations! You've won a free iPhone. Click this link immediately to claim your prize.'\n",
            "Prediction: HAM\n",
            "Email: 'Hey, just following up on our meeting yesterday. Could you send me the revised document by 5 pm?'\n",
            "Prediction: HAM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "# Download stopwords if not already present\n",
        "try:\n",
        "    stopwords.words('english')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "# --- 1. Load and Clean Data ---\n",
        "try:\n",
        "    df = pd.read_csv('/content/email_spam.csv', encoding='latin-1')\n",
        "\n",
        "    # Keep only required columns\n",
        "    df = df[['type', 'text']].rename(columns={'type': 'label'})\n",
        "    df.dropna(subset=['label', 'text'], inplace=True)\n",
        "\n",
        "    # Print original label values\n",
        "    print(\"Original label values:\", df['label'].unique())\n",
        "\n",
        "    # Normalize and map labels\n",
        "    df['label'] = df['label'].str.lower().str.strip()\n",
        "    df['label'] = df['label'].replace({\n",
        "        'ham': 0, 'not spam': 0,\n",
        "        'spam': 1\n",
        "    })\n",
        "\n",
        "    # Drop unmapped labels\n",
        "    df.dropna(subset=['label'], inplace=True)\n",
        "    df['label'] = df['label'].astype(int)\n",
        "\n",
        "    print(\"\\nLabel Distribution:\\n\", df['label'].value_counts())\n",
        "\n",
        "    # --- 2. Preprocessing Function ---\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    def preprocess_text(text):\n",
        "        text = str(text).lower()\n",
        "        text = re.sub(r'[^a-z]', ' ', text)\n",
        "        words = text.split()\n",
        "        words = [word for word in words if word not in stop_words]\n",
        "        return ' '.join(words)\n",
        "\n",
        "    df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "    # --- 3. Split Data ---\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        df['cleaned_text'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
        "    )\n",
        "\n",
        "    # --- 4. Vectorization ---\n",
        "    vectorizer = CountVectorizer(max_features=5000)\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)\n",
        "    X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "    # --- 5. Train Model ---\n",
        "    model = MultinomialNB()\n",
        "    model.fit(X_train_vec, y_train)\n",
        "\n",
        "    # --- 6. Evaluate Model ---\n",
        "    y_pred = model.predict(X_test_vec)\n",
        "    print(\"\\n--- Evaluation ---\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['Ham', 'Spam']))\n",
        "\n",
        "    # --- 7. Live Prediction Function ---\n",
        "    def predict_spam(text_to_check):\n",
        "        cleaned = preprocess_text(text_to_check)\n",
        "        vector = vectorizer.transform([cleaned])\n",
        "        prediction = model.predict(vector)[0]\n",
        "        return \"SPAM\" if prediction == 1 else \"HAM\"\n",
        "\n",
        "    # --- 8. Test Predictions ---\n",
        "    test_email_spam = \"Congratulations! You've won a free iPhone. Click this link immediately to claim your prize.\"\n",
        "    test_email_ham = \"Hey, just following up on our meeting yesterday. Could you send me the revised document by 5 pm?\"\n",
        "\n",
        "    print(\"\\n--- Live Predictions ---\")\n",
        "    print(f\"SPAM Email Prediction: {predict_spam(test_email_spam)}\")\n",
        "    print(f\"HAM Email Prediction: {predict_spam(test_email_ham)}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'email_spam.csv' not found. Please ensure the file is in the correct directory.\")\n"
      ],
      "metadata": {
        "id": "fbHRn1_dGuuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0183779-eead-44d2-c44e-9a94633c036d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original label values: ['spam' 'not spam']\n",
            "\n",
            "Label Distribution:\n",
            " label\n",
            "0    58\n",
            "1    26\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Evaluation ---\n",
            "Accuracy: 0.7059\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Ham       0.71      1.00      0.83        12\n",
            "        Spam       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.71        17\n",
            "   macro avg       0.35      0.50      0.41        17\n",
            "weighted avg       0.50      0.71      0.58        17\n",
            "\n",
            "\n",
            "--- Live Predictions ---\n",
            "SPAM Email Prediction: SPAM\n",
            "HAM Email Prediction: HAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4194605138.py:29: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['label'] = df['label'].replace({\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "# Download stopwords if not already present\n",
        "try:\n",
        "    stopwords.words('english')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "try:\n",
        "    # Load dataset\n",
        "    df = pd.read_csv('/content/email_spam.csv', encoding='latin-1')\n",
        "\n",
        "    # Keep only required columns and drop NaNs\n",
        "    df = df[['type', 'text']].rename(columns={'type': 'label'})\n",
        "    df.dropna(subset=['label', 'text'], inplace=True)\n",
        "\n",
        "    # Show original labels\n",
        "    print(\"Original label values:\", df['label'].unique())\n",
        "\n",
        "    # Map labels and fix future warning by adding infer_objects()\n",
        "    df['label'] = df['label'].str.lower().str.strip()\n",
        "    df['label'] = df['label'].replace({\n",
        "        'ham': 0, 'not spam': 0,\n",
        "        'spam': 1\n",
        "    }).infer_objects()\n",
        "\n",
        "    # Drop rows where mapping failed and convert to int\n",
        "    df.dropna(subset=['label'], inplace=True)\n",
        "    df['label'] = df['label'].astype(int)\n",
        "\n",
        "    print(\"\\nLabel Distribution:\\n\", df['label'].value_counts())\n",
        "\n",
        "    # Preprocessing function\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    def preprocess_text(text):\n",
        "        text = str(text).lower()\n",
        "        text = re.sub(r'[^a-z]', ' ', text)\n",
        "        words = text.split()\n",
        "        words = [word for word in words if word not in stop_words]\n",
        "        return ' '.join(words)\n",
        "\n",
        "    df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "    # Stratified split to maintain label balance\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        df['cleaned_text'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
        "    )\n",
        "\n",
        "    # Vectorization\n",
        "    vectorizer = CountVectorizer(max_features=5000)\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)\n",
        "    X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "    # Train model\n",
        "    model = MultinomialNB()\n",
        "    model.fit(X_train_vec, y_train)\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model.predict(X_test_vec)\n",
        "\n",
        "    # Evaluate with zero_division=0 to suppress warnings\n",
        "    print(\"\\n--- Model Evaluation ---\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['Ham', 'Spam'], zero_division=0))\n",
        "\n",
        "    # Function to predict new emails\n",
        "    def predict_spam(text_to_check):\n",
        "        cleaned = preprocess_text(text_to_check)\n",
        "        vector = vectorizer.transform([cleaned])\n",
        "        prediction = model.predict(vector)[0]\n",
        "        return \"SPAM\" if prediction == 1 else \"HAM\"\n",
        "\n",
        "    # Test predictions\n",
        "    test_email_spam = \"Congratulations! You've won a free iPhone. Click this link immediately to claim your prize.\"\n",
        "    test_email_ham = \"Hey, just following up on our meeting yesterday. Could you send me the revised document by 5 pm?\"\n",
        "\n",
        "    print(\"\\n--- Live Predictions ---\")\n",
        "    print(f\"SPAM Email Prediction: {predict_spam(test_email_spam)}\")\n",
        "    print(f\"HAM Email Prediction: {predict_spam(test_email_ham)}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'email_spam.csv' not found. Please ensure the file is in the correct directory.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43uiV-NH7xWz",
        "outputId": "bfe9a45f-d34e-4661-f455-6bed9b7cceec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original label values: ['spam' 'not spam']\n",
            "\n",
            "Label Distribution:\n",
            " label\n",
            "0    58\n",
            "1    26\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Model Evaluation ---\n",
            "Accuracy: 0.7059\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Ham       0.71      1.00      0.83        12\n",
            "        Spam       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.71        17\n",
            "   macro avg       0.35      0.50      0.41        17\n",
            "weighted avg       0.50      0.71      0.58        17\n",
            "\n",
            "\n",
            "--- Live Predictions ---\n",
            "SPAM Email Prediction: SPAM\n",
            "HAM Email Prediction: HAM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2448892278.py:29: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['label'] = df['label'].replace({\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XHX5qhbi8gnq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}